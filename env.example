# =============================================================================
# CONFIGURACIÓN DE API KEYS - LLM Providers
# =============================================================================
# Clave API de Anthropic (Claude) - REQUERIDA si LLM_PROVIDER=anthropic
# Obtén tu clave en: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Clave API de OpenAI - REQUERIDA si LLM_PROVIDER=openai
# Obtén tu clave en: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Proveedor de LLM a utilizar: "openai" o "anthropic"
LLM_PROVIDER=anthropic

# Modelo de LLM a utilizar
# Para Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229, etc.
# Para OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo, etc.
LLM_MODEL=claude-3-5-sonnet-20241022


# =============================================================================
# API KEYS DE JOB BOARDS (Opcionales)
# =============================================================================
# Clave API de LinkedIn (opcional)
# Requerida solo si usas la API oficial de LinkedIn
LINKEDIN_API_KEY=

# Clave API de Indeed (DESHABILITADO)
# Indeed está deshabilitado por defecto debido a bloqueos frecuentes y difícil acceso
# INDEED_API_KEY=

# Clave API de RemoteOK (opcional)
# RemoteOK tiene una API pública, pero puedes usar una clave si tienes acceso premium
REMOTEOK_API_KEY=


# =============================================================================
# CONFIGURACIÓN DE BÚSQUEDA
# =============================================================================
# Número máximo de trabajos a buscar por fuente
MAX_JOBS_PER_SOURCE=50

# Score mínimo de coincidencia para considerar un trabajo relevante (0-100)
MIN_MATCH_SCORE=60

# Timeout para búsquedas en segundos
SEARCH_TIMEOUT=30


# =============================================================================
# CONFIGURACIÓN DE SCRAPING
# =============================================================================
# Delay entre requests en segundos
SCRAPING_DELAY=2.0

# Número máximo de reintentos en caso de error
MAX_RETRIES=3

# Ejecutar navegador en modo headless (sin interfaz gráfica)
# true = sin interfaz (recomendado para servidores)
# false = con interfaz (útil para debugging)
HEADLESS_BROWSER=true


# =============================================================================
# CONFIGURACIÓN ANTI-BOT BÁSICA
# =============================================================================
# Rotar User-Agent para evitar detección
USE_USER_AGENT_ROTATION=true

# Habilitar delays aleatorios entre requests
RANDOM_DELAY_ENABLED=true

# Delay mínimo en segundos (usado con RANDOM_DELAY_ENABLED)
MIN_DELAY=1.5

# Delay máximo en segundos (usado con RANDOM_DELAY_ENABLED)
MAX_DELAY=4.0

# Usar proxies para evitar bloqueos (requiere PROXY_LIST)
USE_PROXIES=false

# Lista de proxies separados por coma
# Formato: http://proxy1:port,http://proxy2:port
PROXY_LIST=

# Habilitar modo stealth del navegador (Playwright)
ENABLE_BROWSER_STEALTH=true

# Simular comportamiento humano (movimientos de mouse, scroll, etc.)
SIMULATE_HUMAN_BEHAVIOR=true


# =============================================================================
# CONFIGURACIÓN ANTI-BOT AVANZADA
# =============================================================================
# Usar circuit breaker para evitar sobrecarga en caso de errores
USE_CIRCUIT_BREAKER=true

# Número de errores antes de activar el circuit breaker
CIRCUIT_BREAKER_THRESHOLD=5

# Tiempo en segundos antes de intentar nuevamente después de activar circuit breaker
CIRCUIT_BREAKER_TIMEOUT=300

# Mantener sesiones persistentes entre requests
USE_SESSION_PERSISTENCE=true

# Usar rate limiting adaptativo basado en respuestas del servidor
USE_ADAPTIVE_RATE_LIMITING=true

# Bypass de fingerprint TLS (requiere curl_cffi)
USE_TLS_FINGERPRINT_BYPASS=false

# Usar headers Referer para simular navegación real
USE_REFERER_HEADERS=true

# Mantener consistencia en fingerprints del navegador
USE_FINGERPRINT_CONSISTENCY=true

# Hacer warm-up de sesión antes de comenzar scraping
USE_SESSION_WARMUP=true

# Generar variaciones de queries usando LLM
USE_QUERY_VARIATIONS=true


# =============================================================================
# PERFIL DE USUARIO (REQUERIDO)
# =============================================================================
# Email del usuario (usado para extracción de emails de contacto)
# REQUERIDO - Debe configurarse en tu archivo .env
USER_EMAIL=your_email@example.com

# Teléfono del usuario
# REQUERIDO - Debe configurarse en tu archivo .env
USER_PHONE=+1234567890


# =============================================================================
# CONFIGURACIÓN DE LOGGING
# =============================================================================
# Nivel de logging: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Archivo de log (opcional, si no se especifica solo se usa consola)
# Ruta relativa o absoluta
LOG_FILE=job_search.log


# =============================================================================
# CONFIGURACIÓN DE CACHE
# =============================================================================
# Habilitar cache de resultados
USE_CACHE=true

# Tiempo de expiración del cache en horas
CACHE_EXPIRY_HOURS=24


# =============================================================================
# OPTIMIZACIÓN DE PERFORMANCE
# =============================================================================
# Modo rápido: Reduce delays y deshabilita algunas características anti-bot
# para acelerar la búsqueda. ADVERTENCIA: Puede aumentar el riesgo de bloqueos.
# true = modo rápido (delays reducidos, sin simulación humana)
# false = modo normal (recomendado para evitar bloqueos)
FAST_MODE=false

# Concurrencia máxima para extracción de emails (número de trabajos procesados en paralelo)
# Valores más altos = más rápido pero mayor uso de recursos y riesgo de rate limiting
# Recomendado: 10-20 para la mayoría de casos
EMAIL_EXTRACTION_CONCURRENCY=10

# Tamaño de batch para procesamiento de emails con LLM (futuro)
# Número de descripciones procesadas en una sola llamada LLM
# Valores más altos = menos llamadas pero más tokens por llamada
EMAIL_BATCH_SIZE=5


# =============================================================================
# CONFIGURACIÓN DE PATHS (Opcional - usar valores por defecto si no se especifican)
# =============================================================================
# Ruta absoluta al archivo CV en formato Markdown
CV_PATH=

# Directorio de salida para resultados HTML
# Por defecto: job_search_agents/results
# OUTPUT_DIR=

# Directorio de datos (profile.json, etc.)
# Por defecto: job_search_agents/data
# DATA_DIR=
